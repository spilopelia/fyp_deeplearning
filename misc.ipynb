{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.load('/home/user/ckwan1/ml/mlsimdata_npy/mlsimdata1/213864.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 32, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,:,:,6:9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import lightning.pytorch as pl\n",
    "from periodic_padding import periodic_padding_3d\n",
    "\n",
    "def crop_tensor(x):\n",
    "\tx = x.narrow(2,1,x.shape[2]-3).narrow(3,1,x.shape[3]-3).narrow(4,1,x.shape[4]-3).contiguous()\n",
    "\treturn x\n",
    "\n",
    "def conv3x3(inplane,outplane, stride=1,padding=0):\n",
    "\treturn nn.Conv3d(inplane,outplane,kernel_size=3,stride=stride,padding=padding,bias=True)\n",
    "    \n",
    "# Assuming conv3x3 and BasicBlock are defined as in your original code.\n",
    "class BasicBlock(nn.Module):\n",
    "\tdef __init__(self,inplane,outplane,stride = 1):\n",
    "\t\tsuper(BasicBlock, self).__init__()\n",
    "\t\tself.conv1 = conv3x3(inplane,outplane,padding=0,stride=stride)\n",
    "\t\tself.bn1 = nn.BatchNorm3d(outplane)\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\t\tx = periodic_padding_3d(x,pad=(1,1,1,1,1,1))\n",
    "\t\tout = self.conv1(x)\n",
    "\t\tout = self.bn1(out)\n",
    "\t\tout = self.relu(out)\n",
    "\t\treturn out\n",
    "\n",
    "\n",
    "class Lpt2NbodyNet(nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super(Lpt2NbodyNet, self).__init__()\n",
    "        self.layer1 = self._make_layer(block, 3, 64, blocks=2, stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, 128, blocks=1, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, 128, blocks=2, stride=1)\n",
    "        self.layer4 = self._make_layer(block, 128, 256, blocks=1, stride=2)\n",
    "        self.layer5 = self._make_layer(block, 256, 256, blocks=2, stride=1)\n",
    "        self.deconv1 = nn.ConvTranspose3d(256, 128, 3, stride=2, padding=0)\n",
    "        self.deconv_batchnorm1 = nn.BatchNorm3d(num_features=128, momentum=0.1)\n",
    "        self.layer6 = self._make_layer(block, 256, 128, blocks=2, stride=1)\n",
    "        self.deconv2 = nn.ConvTranspose3d(128, 64, 3, stride=2, padding=0)\n",
    "        self.deconv_batchnorm2 = nn.BatchNorm3d(num_features=64, momentum=0.1)\n",
    "        self.layer7 = self._make_layer(block, 128, 64, blocks=2, stride=1)\n",
    "        self.deconv4 = nn.ConvTranspose3d(64, 3, 1, stride=1, padding=0)\n",
    "\n",
    "    def _make_layer(self, block, inplanes, outplanes, blocks, stride=1):\n",
    "        layers = []\n",
    "        for _ in range(blocks):\n",
    "            layers.append(block(inplanes, outplanes, stride=stride))\n",
    "            inplanes = outplanes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.layer1(x)\n",
    "        x = self.layer2(x1)\n",
    "        x2 = self.layer3(x)\n",
    "        x = self.layer4(x2)\n",
    "        x = self.layer5(x)\n",
    "        x = periodic_padding_3d(x, pad=(0, 1, 0, 1, 0, 1))\n",
    "        x = nn.functional.relu(self.deconv_batchnorm1(crop_tensor(self.deconv1(x))), inplace=True)\n",
    "        x = torch.cat((x, x2), dim=1)\n",
    "        x = self.layer6(x)\n",
    "        x = periodic_padding_3d(x, pad=(0, 1, 0, 1, 0, 1))\n",
    "        x = nn.functional.relu(self.deconv_batchnorm2(crop_tensor(self.deconv2(x))), inplace=True)\n",
    "        x = torch.cat((x, x1), dim=1)\n",
    "        x = self.layer7(x)\n",
    "        x = self.deconv4(x)\n",
    "        return x\n",
    "\n",
    "class UNet3D(nn.Module):  \n",
    "    def __init__(self, block, num_layers=2, base_filters=64, blocks_per_layer=2):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.decoders = nn.ModuleList()\n",
    "        \n",
    "        # Encoder path\n",
    "        init_channels = 3\n",
    "        out_channels = base_filters\n",
    "        self.init_conv = self._make_layer(block, init_channels, out_channels, blocks=blocks_per_layer, stride=1)\n",
    "        for _ in range(num_layers):\n",
    "            self.encoders.append(self._make_layer(block, out_channels, out_channels*2, blocks=1, stride=2))\n",
    "            self.encoders.append(self._make_layer(block, out_channels*2, out_channels*2, blocks=blocks_per_layer, stride=1))\n",
    "            out_channels *= 2\n",
    "\n",
    "        # Decoder path\n",
    "        for _ in range(num_layers):\n",
    "            self.decoders.append(nn.ConvTranspose3d(out_channels, out_channels//2, kernel_size=3, stride=2, padding=0))\n",
    "            self.decoders.append(self._make_layer(block, out_channels, out_channels//2, blocks=blocks_per_layer, stride=1))\n",
    "            out_channels //= 2\n",
    "\n",
    "        self.final_conv = nn.ConvTranspose3d(out_channels, 3, 1, stride=1, padding=0)\n",
    "\n",
    "        # Predefine BatchNorm3d and ReLU layers for each decoder step\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        for i in range(num_layers):\n",
    "            self.batch_norms.insert(0, nn.BatchNorm3d(base_filters * (2 ** i)))  # Adjust channels accordingly\n",
    "\n",
    "    def _make_layer(self, block, inplanes, outplanes, blocks, stride=1):\n",
    "        layers = []\n",
    "        for _ in range(blocks):\n",
    "            layers.append(block(inplanes, outplanes, stride=stride))\n",
    "            inplanes = outplanes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_outputs = []\n",
    "\n",
    "        x = self.init_conv(x)\n",
    "        encoder_outputs.append(x)\n",
    "        \n",
    "        # Encoding path\n",
    "        for i in range(0, len(self.encoders), 2):\n",
    "            x = self.encoders[i](x)  # Compression layer\n",
    "            x = self.encoders[i + 1](x)  # Non-compression layer\n",
    "            encoder_outputs.append(x)\n",
    "\n",
    "        # Decoding path\n",
    "        for i in range(0, len(self.decoders), 2):\n",
    "            x = periodic_padding_3d(x, pad=(0, 1, 0, 1, 0, 1))  # Assuming this is a custom function\n",
    "            x = self.decoders[i](x)  # Transpose Conv layer\n",
    "            x = crop_tensor(x)  # Assuming this is a custom function to crop the tensor\n",
    "            \n",
    "            # Use the pre-defined BatchNorm3d and ReLU layers\n",
    "            x = self.batch_norms[i // 2](x)  # BatchNorm\n",
    "            x = nn.ReLU(inplace=True)(x)  # ReLU\n",
    "            \n",
    "            # Skip connection with encoder outputs\n",
    "            x = torch.cat((x, encoder_outputs[len(encoder_outputs)-2-i//2]), dim=1)  # Skip connection\n",
    "            \n",
    "            x = self.decoders[i + 1](x)  # Non-compression layer\n",
    "\n",
    "        # Final 1x1 Conv\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, block, num_layers=2, base_channels=64):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.decoders = nn.ModuleList()\n",
    "        \n",
    "        # Encoder path\n",
    "        init_channels = 3\n",
    "        out_channels = base_channels\n",
    "        self.init_conv = self._make_layer(block, init_channels, out_channels, blocks=2, stride=1)\n",
    "        print(f\"Initial conv output channels: {out_channels}\")\n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            self.encoders.append(self._make_layer(block, out_channels, out_channels*2, blocks=1, stride=2))\n",
    "            self.encoders.append(self._make_layer(block, out_channels*2, out_channels*2, blocks=2, stride=1))\n",
    "            out_channels *= 2\n",
    "        \n",
    "        # Decoder path\n",
    "        for _ in range(num_layers):\n",
    "            self.decoders.append(nn.ConvTranspose3d(out_channels, out_channels//2, kernel_size=3, stride=2, padding=0))\n",
    "            self.decoders.append(self._make_layer(block, out_channels, out_channels//2, blocks=2, stride=1))\n",
    "            out_channels //= 2\n",
    "\n",
    "        self.final_conv = nn.ConvTranspose3d(out_channels, 3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def _make_layer(self, block, inplanes, outplanes, blocks, stride=1):\n",
    "        layers = []\n",
    "        for _ in range(blocks):\n",
    "            layers.append(block(inplanes, outplanes, stride=stride))\n",
    "            inplanes = outplanes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_outputs = []\n",
    "\n",
    "        x = self.init_conv(x)\n",
    "        print(f\"After initial conv: {x.shape}\")\n",
    "        encoder_outputs.append(x)\n",
    "\n",
    "        # Encoding path\n",
    "        for i in range(0, len(self.encoders), 2):\n",
    "            x = self.encoders[i](x)  # Compression layer\n",
    "            print(f\"After encoder compression {i//2}: {x.shape}\")\n",
    "            x = self.encoders[i + 1](x)  # Non-compression layer\n",
    "            print(f\"After encoder non-compression {i//2}: {x.shape}\")\n",
    "            encoder_outputs.append(x)\n",
    "\n",
    "        # Decoding path\n",
    "        for i in range(0, len(self.decoders), 2):\n",
    "            x = periodic_padding_3d(x, pad=(0, 1, 0, 1, 0, 1))\n",
    "            print(f\"After periodic padding before transpose conv {i//2}: {x.shape}\")\n",
    "            x = self.decoders[i](x)  # Transpose Conv layer\n",
    "            print(f\"After transpose conv {i//2}: {x.shape}\")\n",
    "            x = crop_tensor(x)  # Crop to match dimensions if necessary\n",
    "            print(f\"After cropping {i//2}: {x.shape}\")\n",
    "            \n",
    "            # BatchNorm and ReLU before concatenation\n",
    "            x = nn.BatchNorm3d(x.shape[1])(x)  # BatchNorm\n",
    "            x = nn.ReLU(inplace=True)(x)  # ReLU\n",
    "            print(f\"After BatchNorm and ReLU {i//2}: {x.shape}\")\n",
    "\n",
    "            x = torch.cat((x, encoder_outputs[len(encoder_outputs)-2-i//2]), dim=1)  # Skip connection\n",
    "            print(f\"After concatenation {i//2}: {x.shape}\")\n",
    "            \n",
    "            x = self.decoders[i + 1](x)  # Non-compression layer\n",
    "            print(f\"After decoder non-compression {i//2}: {x.shape}\")\n",
    "\n",
    "        # Final 1x1 Conv\n",
    "        x = self.final_conv(x)\n",
    "        print(f\"Final output shape: {x.shape}\")\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UNet3D.__init__() got an unexpected keyword argument 'base_channels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m UNet3D(block\u001b[38;5;241m=\u001b[39mBasicBlock, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, base_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: UNet3D.__init__() got an unexpected keyword argument 'base_channels'"
     ]
    }
   ],
   "source": [
    "model = UNet3D(block=BasicBlock, num_layers=3, base_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet3D(block=BasicBlock, num_layers=3, base_filters=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 3, 32, 32, 32)  # Change the dimensions as needed\n",
    "input_tensor = torch.rand(input_shape)  # Create a random input tensor\n",
    "\n",
    "# Run a forward pass through the model\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet3D(\n",
       "  (encoders): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleList(\n",
       "    (0): ConvTranspose3d(512, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvTranspose3d(256, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
       "    (3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (init_conv): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): ConvTranspose3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (batch_norms): ModuleList(\n",
       "    (0): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_62867/2134185488.py\u001b[0m(120)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    118 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    119 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 120 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Skip connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    121 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    122 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Non-compression layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "*** Newest frame\n",
      "*** Newest frame\n"
     ]
    }
   ],
   "source": [
    "%debug \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lpt2NbodyNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (deconv1): ConvTranspose3d(256, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
      "  (deconv_batchnorm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer6): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (deconv2): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n",
      "  (deconv_batchnorm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer7): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (deconv4): ConvTranspose3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Lpt2NbodyNet(block=BasicBlock)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d3m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
